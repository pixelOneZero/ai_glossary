Backward propogation:

Biases:

Binary classification: An algorithm that returns 0 or 1 provided with given input x.

Cost function: Quantifies, for parameters, the average of the sum of loss functions.

CNN: Convolutional neural network.

Densely connected:

Epoch:

Features: Dimensions of data

Forward propogation:

Gradient descent: Describes the rate of learning.

Hidden layers:

Hyperparameter:

Input layer:

LSTM: Long short-term memory.

Logistic regression: An algorithm for binary classification.

Loss function: Quantifies, for a single training example, the difference between the estimate and actual result.

m: The size of the training data set

Neuron:

NLP: Natural language processing

NN: Neural network.

Optimization:

Regularization:

RelU: Rectified linear units.

RNN: Recurrent neural network.

Sigmoid: Function characterized by a flat gradient on the left and right of it's graph.

Tuning:

Weights: 